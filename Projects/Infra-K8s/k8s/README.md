# Kubernetes Auto-Scaling Demo

Demo de auto-scaling en Kubernetes con procesamiento distribuido de im√°genes.

## üìö ¬øQu√© es HPA?

**HPA** = **Horizontal Pod Autoscaler**

Es un componente de Kubernetes que **autom√°ticamente** ajusta el n√∫mero de pods (r√©plicas) de un Deployment bas√°ndose en m√©tricas como:
- CPU utilization (uso de CPU)
- Memory utilization (uso de memoria)
- M√©tricas custom (ej: longitud de cola)

**Ejemplo en este demo:**
- **Min replicas**: 1 worker
- **Max replicas**: 10 workers
- **Target CPU**: 15% (escala si CPU > 15%)
- **Resultado**: Cuando hay carga, Kubernetes crea m√°s workers autom√°ticamente. Cuando baja la carga, los elimina.

## üìÅ Archivos del Demo

### Esenciales (Kubernetes)
- `demo.py` - **Script principal del demo**
- `redis-deployment.yaml` - Redis como cola de tareas
- `api-deployment.yaml` - API Django
- `worker-deployment.yaml` - Workers para Mac/Linux
- `worker-deployment-windows.yaml` - Workers para Windows
- `metrics-server.yaml` - Metrics Server para HPA

### Opcionales
- `stress_test.py` - Stress test personalizado (avanzado)
- `PLATFORM_NOTES.md` - Notas t√©cnicas de la plataforma

## üöÄ Quick Start

### ‚ö†Ô∏è Primera Vez (Construir im√°genes Docker)

Si las im√°genes Docker NO existen, construirlas primero:

```bash
# Desde la carpeta padre
cd Projects/Infra-K8s
python build.py

# Verificar que se crearon
docker images | grep projects
# Debes ver: projects-api-final:latest y projects-worker-final:latest
```

### Windows

```bash
# 1. Configurar ruta en worker-deployment-windows.yaml (una sola vez)
# Editar l√≠neas 41-46 con TU usuario y ruta

# 2. Ejecutar demo
cd Projects/Infra-K8s/k8s
python demo.py
```

### Mac/Linux

```bash
cd Projects/Infra-K8s/k8s
python demo.py
```

## üìÇ Estructura Requerida en Windows

```
C:\Users\TU_USUARIO\...\Infra-K8s\static\
‚îú‚îÄ‚îÄ images\              ‚Üê Im√°genes de entrada aqu√≠
‚îÇ   ‚îú‚îÄ‚îÄ sample.jpg
‚îÇ   ‚îî‚îÄ‚îÄ sample_4k.jpg
‚îî‚îÄ‚îÄ processed\           ‚Üê Im√°genes procesadas van aqu√≠
```

## ‚öôÔ∏è Configuraci√≥n

El `demo.py` autom√°ticamente:
- ‚úÖ Detecta tu plataforma (Windows/Mac/Linux)
- ‚úÖ Usa el deployment correcto
- ‚úÖ Configura HPA para auto-scaling (CPU target: 15%)
- ‚úÖ Env√≠a 100 tareas pesadas
- ‚úÖ Monitorea escalado durante 4 minutos

## üìä Qu√© Esperar

```
Workers: 1 ‚Üí 2 ‚Üí 4 ‚Üí 6 ‚Üí 8+  (escalado)
         ‚Üì (despu√©s de procesar)
Workers: 8 ‚Üí 6 ‚Üí 4 ‚Üí 2 ‚Üí 1  (descalado)
```

Duraci√≥n: ~5-7 minutos

## üìà Monitorear Auto-Scaling en Tiempo Real

### Ver estado del HPA
```bash
# Estado actual del HPA (r√©plicas, CPU%, targets)
kubectl get hpa

# Output ejemplo:
# NAME         REFERENCE              TARGETS   MINPODS  MAXPODS  REPLICAS
# worker-hpa   Deployment/worker...   45%/15%   1        10       4

# Ver en tiempo real (actualiza cada 2 segundos)
watch -n 2 kubectl get hpa

# Detalles completos del HPA
kubectl describe hpa worker-hpa
```

### Ver r√©plicas de workers
```bash
# Ver pods actuales
kubectl get pods -l app=image-worker

# Ver en tiempo real
kubectl get pods -l app=image-worker -w

# Contar r√©plicas
kubectl get deployment worker-deployment
```

### Ver m√©tricas de CPU/Memory
```bash
# M√©tricas de todos los workers
kubectl top pods -l app=image-worker

# Ver en tiempo real
watch -n 2 'kubectl top pods -l app=image-worker'
```

### Ver eventos de escalado
```bash
# Ver √∫ltimos eventos de scaling
kubectl describe hpa worker-hpa | grep -A 10 Events

# Output ejemplo:
#   Normal  SuccessfulRescale  2m   HPA  New size: 4; reason: cpu > target
#   Normal  SuccessfulRescale  5m   HPA  New size: 2; reason: All metrics below target
```

### Dashboard completo (en una terminal)
```bash
# Comando combinado que muestra todo
watch -n 2 'echo "=== HPA ===" && kubectl get hpa && echo && echo "=== WORKERS ===" && kubectl get pods -l app=image-worker && echo && echo "=== METRICS ===" && kubectl top pods -l app=image-worker'
```

## üêõ Troubleshooting

```bash
# Ver estado
kubectl get pods -n default
kubectl get hpa

# Ver logs
kubectl logs -l app=image-worker --tail=50

# Verificar vol√∫menes (Windows)
kubectl exec <worker-pod> -- ls -la /app/static/images/

# Ver tareas en Redis
kubectl exec deployment/redis-deployment -- redis-cli LLEN tasks:completed
```

## üìñ M√°s Informaci√≥n

Ver documentaci√≥n completa en `../README.md` del proyecto.


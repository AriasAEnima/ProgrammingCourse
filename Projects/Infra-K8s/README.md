# ğŸ–¼ï¸ Kubernetes Auto-Scaling Demo

Demo de **auto-scaling automÃ¡tico** en Kubernetes con procesamiento distribuido de imÃ¡genes.

## ğŸ¯ Â¿QuÃ© hace este demo?

Muestra **auto-scaling real** de workers en Kubernetes:
- ğŸ“ˆ **Scale UP**: Cuando hay carga, Kubernetes crea mÃ¡s workers automÃ¡ticamente
- ğŸ“‰ **Scale DOWN**: Cuando baja la carga, elimina workers gradualmente
- ğŸ“Š **Basado en mÃ©tricas reales**: CPU y memoria de los pods

## ğŸš€ Quick Start

### 1ï¸âƒ£ Construir imÃ¡genes Docker (solo primera vez)

```bash
cd Projects/Infra-K8s
python build.py

# Verificar que se crearon
docker images | grep projects
# Debes ver:
#   projects-api-final:latest
#   projects-worker-final:latest
```

### 2ï¸âƒ£ Ejecutar el demo

**Windows:**
```bash
cd k8s
python demo.py
```

**Mac/Linux:**
```bash
cd k8s
python demo.py
```

### 3ï¸âƒ£ Ver resultados

El demo muestra automÃ¡ticamente durante 4 minutos:
- âœ… Pods escalando (1 â†’ 2 â†’ 4 â†’ 6+)
- âœ… MÃ©tricas de CPU/Memory
- âœ… Estado del HPA
- âœ… Descalado gradual al final

## ğŸ“‹ Archivos Necesarios

### Esenciales
```
Infra-K8s/
â”œâ”€â”€ build.py                        # Construir imÃ¡genes (una vez)
â”œâ”€â”€ k8s/
â”‚   â”œâ”€â”€ demo.py                     # â­ DEMO PRINCIPAL
â”‚   â”œâ”€â”€ redis-deployment.yaml       # Redis
â”‚   â”œâ”€â”€ api-deployment.yaml         # API
â”‚   â”œâ”€â”€ worker-deployment.yaml      # Workers (Mac/Linux)
â”‚   â”œâ”€â”€ worker-deployment-windows.yaml  # Workers (Windows)
â”‚   â”œâ”€â”€ metrics-server.yaml         # Metrics Server
â”‚   â””â”€â”€ README.md                   # DocumentaciÃ³n del demo
â”‚
â”œâ”€â”€ docker/                         # Dockerfiles
â”œâ”€â”€ django_image_server/            # Django API
â”œâ”€â”€ image_api/                      # Endpoints
â”œâ”€â”€ distributed/                    # Redis queue
â”œâ”€â”€ workers/                        # Worker code
â”œâ”€â”€ static/images/                  # ImÃ¡genes de entrada
â””â”€â”€ static/processed/               # ImÃ¡genes procesadas
```

### Opcionales
- `stress_test.py` - Stress test personalizado (avanzado)

## ğŸ“š Â¿QuÃ© es HPA?

**HPA = Horizontal Pod Autoscaler**

Ajusta automÃ¡ticamente el nÃºmero de pods basÃ¡ndose en:
- CPU utilization (uso de CPU)
- Memory utilization (uso de memoria)

**Ejemplo:**
- Min: 1 worker
- Max: 10 workers  
- Target CPU: 30%
- **Resultado**: Si CPU > 30%, Kubernetes crea mÃ¡s workers automÃ¡ticamente

## ğŸ“Š Arquitectura

```
Cliente â†’ API Service â†’ Redis Queue â†’ Workers (auto-scaling)
                                         â†“
                                        HPA
                                         â†“
                                   Metrics Server
```

## ğŸ› Troubleshooting

### Demo no escala pods

```bash
# Ver estado del HPA
kubectl get hpa

# Si muestra <unknown>, instalar Metrics Server:
kubectl apply -f metrics-server.yaml

# Ver mÃ©tricas de pods
kubectl top pods
```

### No se procesan imÃ¡genes (Windows)

```bash
# 1. Verificar que exista el directorio con subdirectorios
dir C:\Users\TU_USUARIO\...\Infra-K8s\static\images

# Estructura requerida:
# static/
# â”œâ”€â”€ images/       â† ImÃ¡genes aquÃ­
# â””â”€â”€ processed/    â† Salida aquÃ­

# 2. Actualizar ruta en worker-deployment-windows.yaml (lÃ­neas 41-46)
# 3. Reiniciar workers
kubectl delete pod -l app=image-worker
```

### Ver logs de workers

```bash
kubectl logs -l app=image-worker --tail=50
kubectl logs -f -l app=image-worker  # Seguir en tiempo real
```

## ğŸ“– DocumentaciÃ³n Detallada

Ver `k8s/README.md` para:
- Monitoreo en tiempo real
- Comandos kubectl Ãºtiles
- Troubleshooting avanzado

---

**ğŸ¯ Un solo comando: `python demo.py` y funciona!** ğŸš€

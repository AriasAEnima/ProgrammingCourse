# âš™ï¸ SesiÃ³n 3: Arquitectura de Workers

## ğŸ¯ Objetivos de la SesiÃ³n (45 min)

1. **Entender el patrÃ³n Worker** para procesamiento
2. **Implementar procesamiento asÃ­ncrono** con asyncio
3. **Logging estructurado** para debugging
4. **Health checks y monitoreo** bÃ¡sico

---

## ğŸ”„ EvoluciÃ³n del Sistema

### Hasta Ahora:
```
SesiÃ³n 1: Filtro individual
SesiÃ³n 2: Pipeline de filtros
```

### Hoy (SesiÃ³n 3):
```
Worker â†’ Toma tareas â†’ Procesa â†’ Reporta resultado
```

### Futuro (Sesiones 4-10):
```
Cliente â†’ Redis Queue â†’ Worker 1
                     â†’ Worker 2  â†’ Sistema Distribuido
                     â†’ Worker N
```

---

## ğŸ—ï¸ Â¿QuÃ© es un Worker?

Un **Worker** es un proceso que:
1. **Espera** tareas en una cola
2. **Procesa** cada tarea (aplica filtros)
3. **Reporta** resultados y estadÃ­sticas
4. **Repite** el ciclo continuamente

**AnalogÃ­a:** Como un empleado en una fÃ¡brica que:
- Toma piezas de la cinta transportadora
- Las procesa
- Las coloca en la salida
- Repite

---

## ğŸ“‚ Estructura del Proyecto

```
session3_workers/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ images/                    # ImÃ¡genes de prueba
â”‚
â”œâ”€â”€ filters/                   # Filtros (de sesiones anteriores)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_filter.py
â”‚   â”œâ”€â”€ blur_filter.py
â”‚   â”œâ”€â”€ brightness_filter.py
â”‚   â”œâ”€â”€ edges_filter.py
â”‚   â””â”€â”€ grayscale_filter.py
â”‚
â”œâ”€â”€ core/                      # Pipeline y Factory
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ filter_pipeline.py
â”‚   â””â”€â”€ filter_factory.py
â”‚
â”œâ”€â”€ workers/                   # ğŸ†• MÃ³dulo de Workers
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_worker.py        # Worker base abstracto
â”‚   â”œâ”€â”€ simple_worker.py      # Worker sÃ­ncrono simple
â”‚   â”œâ”€â”€ async_worker.py       # Worker asÃ­ncrono
â”‚   â””â”€â”€ task_queue.py         # Cola de tareas (simulada)
â”‚
â”œâ”€â”€ demos/
â”‚   â”œâ”€â”€ demo_simple_worker.py
â”‚   â”œâ”€â”€ demo_async_worker.py
â”‚   â””â”€â”€ demo_multiple_workers.py
â”‚
â””â”€â”€ output/
```

---

## ğŸ”§ Conceptos Clave

### 1. Base Worker (PatrÃ³n Template)

```python
class BaseWorker(ABC):
    """Clase base para todos los workers."""
    
    def __init__(self, worker_id: str):
        self.worker_id = worker_id
        self.is_running = False
        self.stats = {
            'tasks_completed': 0,
            'tasks_failed': 0,
            'total_time': 0
        }
    
    @abstractmethod
    def process_task(self, task):
        """Procesa una tarea especÃ­fica."""
        pass
    
    def start(self):
        """Inicia el worker."""
        self.is_running = True
        while self.is_running:
            task = self.get_next_task()
            if task:
                self.process_task(task)
    
    def stop(self):
        """Detiene el worker gracefully."""
        self.is_running = False
```

**Â¿Por quÃ© esta estructura?**
- âœ… Comportamiento comÃºn en clase base
- âœ… LÃ³gica especÃ­fica en subclases
- âœ… FÃ¡cil de extender
- âœ… Consistente con otros workers

---

### 2. Simple Worker (SÃ­ncrono)

```python
class SimpleWorker(BaseWorker):
    """Worker que procesa tareas de manera sÃ­ncrona."""
    
    def __init__(self, worker_id, pipeline):
        super().__init__(worker_id)
        self.pipeline = pipeline
    
    def process_task(self, task):
        """Procesa una tarea con el pipeline."""
        image_path = task['image_path']
        
        # Cargar imagen
        image = Image.open(image_path)
        
        # Aplicar pipeline
        result, stats = self.pipeline.apply(image)
        
        # Guardar resultado
        output_path = task['output_path']
        result.save(output_path)
        
        # Actualizar estadÃ­sticas
        self.stats['tasks_completed'] += 1
        self.stats['total_time'] += stats['total_time']
```

**CaracterÃ­sticas:**
- Procesa una tarea a la vez
- Bloquea mientras procesa
- Simple de entender
- Bueno para empezar

---

### 3. Async Worker (AsÃ­ncrono)

```python
class AsyncWorker(BaseWorker):
    """Worker que procesa tareas de manera asÃ­ncrona."""
    
    async def process_task(self, task):
        """Procesa tarea de forma asÃ­ncrona."""
        # Puede procesar mÃºltiples tareas concurrentemente
        image = await self.load_image_async(task['image_path'])
        result = await self.apply_pipeline_async(image)
        await self.save_result_async(result, task['output_path'])
```

**Ventajas:**
- Puede procesar mÃºltiples tareas
- No bloquea en I/O (lectura/escritura)
- MÃ¡s eficiente
- Preparado para sistema distribuido

---

### 4. Task Queue (Cola de Tareas)

```python
class TaskQueue:
    """Cola de tareas para workers."""
    
    def __init__(self):
        self.queue = deque()
        self.completed = []
        self.failed = []
    
    def add_task(self, task):
        """AÃ±ade tarea a la cola."""
        self.queue.append(task)
    
    def get_task(self):
        """Obtiene prÃ³xima tarea."""
        if self.queue:
            return self.queue.popleft()
        return None
    
    def mark_completed(self, task, result):
        """Marca tarea como completada."""
        self.completed.append({
            'task': task,
            'result': result,
            'timestamp': time.time()
        })
```

**En esta sesiÃ³n:** Cola en memoria (lista Python)  
**En SesiÃ³n 4:** Redis (cola distribuida)  
**En SesiÃ³n 7:** Kubernetes Jobs

---

## ğŸ¨ Logging Estructurado

### Â¿Por quÃ© logging?

En sistemas distribuidos necesitas saber:
- Â¿QuÃ© worker procesÃ³ quÃ© tarea?
- Â¿CuÃ¡nto tardÃ³ cada tarea?
- Â¿Hubo errores? Â¿CuÃ¡les?
- Â¿CuÃ¡l es el estado del sistema?

### Ejemplo de Log Estructurado:

```python
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - [%(name)s] - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)

# Logs informativos
logger.info(f"Worker {self.worker_id} iniciado")
logger.info(f"Procesando tarea {task_id}")

# Logs de performance
logger.info(f"Tarea completada en {duration:.3f}s")

# Logs de errores
logger.error(f"Error procesando tarea: {error}")
```

**Output:**
```
2024-11-20 18:30:15,123 - [Worker-1] - INFO - Worker worker-1 iniciado
2024-11-20 18:30:15,456 - [Worker-1] - INFO - Procesando tarea task-001
2024-11-20 18:30:16,789 - [Worker-1] - INFO - Tarea completada en 1.333s
```

---

## ğŸ¥ Health Checks

### Â¿QuÃ© es un Health Check?

Mecanismo para saber si un worker estÃ¡:
- âœ… **Healthy**: Funcionando correctamente
- âš ï¸  **Degraded**: Funcionando pero con problemas
- âŒ **Unhealthy**: No funciona

### ImplementaciÃ³n Simple:

```python
class WorkerHealthCheck:
    """Monitorea la salud de un worker."""
    
    def __init__(self, worker):
        self.worker = worker
        self.last_heartbeat = time.time()
    
    def is_healthy(self):
        """Verifica si el worker estÃ¡ saludable."""
        # Â¿EstÃ¡ corriendo?
        if not self.worker.is_running:
            return False
        
        # Â¿Ha procesado tareas recientemente?
        time_since_heartbeat = time.time() - self.last_heartbeat
        if time_since_heartbeat > 60:  # 60 segundos sin actividad
            return False
        
        # Â¿Tiene demasiados fallos?
        failure_rate = self.worker.stats['tasks_failed'] / max(1, self.worker.stats['tasks_completed'])
        if failure_rate > 0.5:  # MÃ¡s del 50% fallan
            return False
        
        return True
    
    def heartbeat(self):
        """Actualiza el Ãºltimo latido."""
        self.last_heartbeat = time.time()
```

---

## ğŸš€ Uso RÃ¡pido

### 1. Worker Simple (SÃ­ncrono):

```bash
python demos/demo_simple_worker.py
```

Muestra un worker procesando tareas de forma secuencial.

### 2. Worker AsÃ­ncrono:

```bash
python demos/demo_async_worker.py
```

Muestra un worker procesando mÃºltiples tareas concurrentemente.

### 3. MÃºltiples Workers:

```bash
python demos/demo_multiple_workers.py
```

Simula varios workers procesando tareas en paralelo.

---

## ğŸ“Š ComparaciÃ³n de Performance

**Procesando 10 imÃ¡genes:**

| Tipo | Tiempo | Ventaja |
|------|--------|---------|
| **Secuencial** | 14.2s | Baseline |
| **Simple Worker** | 14.5s | +2% (overhead logging) |
| **Async Worker** | 8.3s | -41% âš¡ (I/O no bloqueante) |
| **3 Workers** | 5.1s | -64% ğŸš€ (paralelismo) |

**ConclusiÃ³n:** Los workers asÃ­ncronos y mÃºltiples workers mejoran significativamente la performance.

---

## ğŸ“ Conceptos Avanzados

### 1. Worker Pool

```python
class WorkerPool:
    """Pool de workers para procesamiento paralelo."""
    
    def __init__(self, num_workers, pipeline):
        self.workers = [
            SimpleWorker(f"worker-{i}", pipeline)
            for i in range(num_workers)
        ]
    
    def process_batch(self, tasks):
        """Distribuye tareas entre workers."""
        for i, task in enumerate(tasks):
            worker_idx = i % len(self.workers)
            self.workers[worker_idx].add_task(task)
```

### 2. Graceful Shutdown

```python
def stop(self):
    """Detiene el worker gracefully."""
    logger.info(f"Worker {self.worker_id} recibiÃ³ seÃ±al de parada")
    
    # Terminar tarea actual
    if self.current_task:
        logger.info("Terminando tarea actual...")
        self.finish_current_task()
    
    # Guardar estadÃ­sticas
    self.save_stats()
    
    # Marcar como detenido
    self.is_running = False
    logger.info(f"Worker {self.worker_id} detenido correctamente")
```

### 3. Error Recovery

```python
def process_task(self, task):
    """Procesa tarea con retry logic."""
    max_retries = 3
    
    for attempt in range(max_retries):
        try:
            result = self._do_process(task)
            return result
        except Exception as e:
            logger.warning(f"Intento {attempt+1} fallÃ³: {e}")
            if attempt == max_retries - 1:
                logger.error(f"Tarea fallÃ³ despuÃ©s de {max_retries} intentos")
                raise
            time.sleep(2 ** attempt)  # Exponential backoff
```

---

## ğŸ”— ConexiÃ³n con Sesiones Futuras

| SesiÃ³n 3 (Hoy) | SesiÃ³n 4 (Redis) | SesiÃ³n 7 (K8s) |
|----------------|------------------|----------------|
| Cola en memoria | Cola en Redis | Kubernetes Jobs |
| Worker local | Worker distribuido | Worker en Pod |
| Health check simple | Health check con Redis | Liveness/Readiness probes |
| Logging bÃ¡sico | Logging centralizado | Logs en cluster |

---

## ğŸ“š PrÃ³xima SesiÃ³n

**SesiÃ³n 4: Redis y Colas de Tareas**
- Instalar y configurar Redis
- Colas distribuidas
- SerializaciÃ³n de tareas
- Estados de tareas (pending, processing, completed, failed)

---

## ğŸ¤” Preguntas Frecuentes

### Â¿Por quÃ© no usar threading?
- Threading en Python tiene GIL (Global Interpreter Lock)
- Asyncio es mÃ¡s eficiente para I/O
- Asyncio es el estÃ¡ndar moderno

### Â¿CuÃ¡ntos workers necesito?
- Depende de:
  - NÃºmero de CPUs
  - Tipo de tareas (CPU-bound vs I/O-bound)
  - Recursos disponibles
- Regla general: `num_workers = num_cpus * 2`

### Â¿CÃ³mo escalar horizontalmente?
- SesiÃ³n 3: MÃºltiples workers en una mÃ¡quina
- SesiÃ³n 5: Workers en mÃºltiples mÃ¡quinas
- SesiÃ³n 8: Auto-scaling en Kubernetes

---

## ğŸ“– Referencias

- [Python asyncio Documentation](https://docs.python.org/3/library/asyncio.html)
- [Worker Pattern](https://en.wikipedia.org/wiki/Worker_pattern)
- [Health Check Patterns](https://microservices.io/patterns/observability/health-check-api.html)
- [Graceful Shutdown](https://cloud.google.com/blog/products/containers-kubernetes/kubernetes-best-practices-terminating-with-grace)


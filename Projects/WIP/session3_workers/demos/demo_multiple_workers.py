#!/usr/bin/env python3
"""
Demo: M√∫ltiples Workers en Paralelo

Este demo muestra:
1. Varios workers procesando de la misma cola
2. Uso de threading para paralelismo
3. Coordinaci√≥n entre workers
4. Estad√≠sticas agregadas
"""

import os
import sys
import time
import threading

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from workers import SimpleWorker, TaskQueue
from core import FilterPipeline
from filters import BlurFilter, BrightnessFilter


def main():
    print("üë• Demo: M√∫ltiples Workers")
    print("=" * 70)
    
    # Verificar imagen
    image_path = "images/sample.jpg"
    if not os.path.exists(image_path):
        print(f"‚ùå No se encontr√≥: {image_path}")
        return
    
    os.makedirs("output", exist_ok=True)
    
    # ========================================================================
    # PASO 1: Crear Pipeline
    # ========================================================================
    print("\nüìã PASO 1: Crear Pipeline")
    print("-" * 70)
    
    pipeline = FilterPipeline([
        BlurFilter(radius=2),
        BrightnessFilter(factor=1.3)
    ])
    
    print(f"‚úÖ Pipeline: {pipeline}")
    
    # ========================================================================
    # PASO 2: Crear Cola con Muchas Tareas
    # ========================================================================
    print("\nüì¶ PASO 2: Crear Cola con 12 Tareas")
    print("-" * 70)
    
    queue = TaskQueue()
    
    # A√±adir 12 tareas
    for i in range(1, 13):
        task_id = queue.add_task({
            'name': f'Task {i}',
            'image_path': image_path,
            'output_path': f'output/multi_worker_task{i}.jpg'
        })
        print(f"‚úÖ Tarea {i:2d} a√±adida: {task_id}")
    
    print(f"\nüìä Cola inicial: {queue}")
    
    # ========================================================================
    # PASO 3: Crear M√∫ltiples Workers
    # ========================================================================
    print("\nüë• PASO 3: Crear 3 Workers")
    print("-" * 70)
    
    num_workers = 3
    workers = []
    threads = []
    
    for i in range(num_workers):
        worker = SimpleWorker(
            worker_id=f'worker-{i+1}',
            pipeline=pipeline,
            queue=queue,
            poll_interval=0.1  # Poll r√°pido para demo
        )
        workers.append(worker)
        print(f"‚úÖ Worker {i+1} creado: {worker.worker_id}")
    
    # ========================================================================
    # PASO 4: Iniciar Workers en Threads
    # ========================================================================
    print("\nüîÑ PASO 4: Iniciando Workers")
    print("=" * 70)
    print("(Los 3 workers procesar√°n tareas en paralelo)")
    print("-" * 70)
    
    start_time = time.time()
    
    # Crear y arrancar threads
    for worker in workers:
        # Crear funci√≥n wrapper que procesa hasta que no haya m√°s tareas
        def worker_function(w):
            w.is_running = True
            w.stats['start_time'] = time.time()
            w.logger.info(f"üöÄ Worker {w.worker_id} iniciado")
            
            while not queue.is_empty() or len(queue.processing) > 0:
                task = queue.get_task(w.worker_id)
                
                if task:
                    w.current_task = task
                    task_id = task.get('id')
                    
                    try:
                        result = w.process_task(task)
                        queue.mark_completed(task_id, result)
                    except Exception as e:
                        queue.mark_failed(task_id, str(e))
                    finally:
                        w.current_task = None
                else:
                    time.sleep(w.poll_interval)
            
            w.is_running = False
        
        thread = threading.Thread(target=worker_function, args=(worker,))
        threads.append(thread)
        thread.start()
        print(f"‚ñ∂Ô∏è  Thread iniciado para {worker.worker_id}")
    
    # Esperar a que todos terminen
    print(f"\n‚è≥ Esperando a que los workers terminen...")
    for thread in threads:
        thread.join()
    
    total_time = time.time() - start_time
    
    print(f"\n‚úÖ Todos los workers han terminado")
    
    # ========================================================================
    # PASO 5: Resultados Agregados
    # ========================================================================
    print("\n" + "=" * 70)
    print("üìä RESULTADOS AGREGADOS")
    print("=" * 70)
    
    queue_stats = queue.get_stats()
    
    print(f"\nüì¶ Cola:")
    print(f"   Total de tareas: {queue_stats['total']}")
    print(f"   ‚úÖ Completadas: {queue_stats['completed']}")
    print(f"   ‚ùå Fallidas: {queue_stats['failed']}")
    print(f"   ‚è±Ô∏è  Tiempo total: {total_time:.3f}s")
    
    print(f"\nüë• Workers (Estad√≠sticas Individuales):")
    print("-" * 70)
    
    total_tasks = 0
    total_processing_time = 0
    
    for i, worker in enumerate(workers, 1):
        stats = worker.get_stats()
        total_tasks += stats['tasks_completed']
        total_processing_time += stats['total_processing_time']
        
        print(f"\n   Worker {i} ({worker.worker_id}):")
        print(f"      Tareas completadas: {stats['tasks_completed']}")
        print(f"      Tiempo de procesamiento: {stats['total_processing_time']:.3f}s")
        
        if stats['tasks_completed'] > 0:
            avg = stats['total_processing_time'] / stats['tasks_completed']
            print(f"      Tiempo promedio: {avg:.3f}s")
    
    # Estad√≠sticas agregadas
    print(f"\nüìä Resumen Agregado:")
    print(f"   Total tareas procesadas: {total_tasks}")
    print(f"   Tiempo total de procesamiento: {total_processing_time:.3f}s")
    print(f"   Tiempo real transcurrido: {total_time:.3f}s")
    
    # Calcular eficiencia
    if total_time > 0:
        efficiency = (total_processing_time / total_time) / num_workers
        speedup = total_processing_time / total_time
        print(f"\n‚ö° Performance:")
        print(f"   Speedup: {speedup:.2f}x")
        print(f"   Eficiencia: {efficiency:.1%}")
        print(f"   Throughput: {total_tasks / total_time:.2f} tareas/segundo")
    
    # Archivos generados
    print(f"\nüìÅ Archivos Generados ({queue_stats['completed']} archivos):")
    output_files = sorted([
        f"output/multi_worker_task{i}.jpg" 
        for i in range(1, 13)
        if os.path.exists(f"output/multi_worker_task{i}.jpg")
    ])
    
    for output_file in output_files[:6]:  # Mostrar primeros 6
        if os.path.exists(output_file):
            size = os.path.getsize(output_file) / 1024
            print(f"   ‚Ä¢ {os.path.basename(output_file)} ({size:.1f} KB)")
    
    if len(output_files) > 6:
        print(f"   ... y {len(output_files) - 6} archivos m√°s")
    
    # ========================================================================
    # An√°lisis
    # ========================================================================
    print("\n" + "=" * 70)
    print("üî¨ AN√ÅLISIS DE PERFORMANCE")
    print("=" * 70)
    
    sequential_time = total_processing_time
    parallel_time = total_time
    theoretical_speedup = num_workers
    actual_speedup = sequential_time / parallel_time
    
    print(f"""
    Escenario: {queue_stats['total']} tareas, {num_workers} workers
    
    Tiempo secuencial (1 worker):
    - Estimado: {sequential_time:.3f}s
    
    Tiempo paralelo ({num_workers} workers):
    - Real: {parallel_time:.3f}s
    
    Speedup te√≥rico: {theoretical_speedup:.1f}x
    Speedup real: {actual_speedup:.2f}x
    
    ¬øPor qu√© no es {theoretical_speedup}x perfecto?
    - Overhead de threading
    - Contenci√≥n en la cola (lock)
    - Tareas no perfectamente balanceadas
    - Python GIL (Global Interpreter Lock)
    
    Nota: Para mejor paralelismo, usar multiprocessing
          (se ver√° en Sesi√≥n 5)
    """)
    
    # ========================================================================
    # Resumen
    # ========================================================================
    print("\n" + "=" * 70)
    print("‚ú® DEMO COMPLETADO")
    print("=" * 70)
    
    print(f"\nüí° Conceptos demostrados:")
    print(f"   ‚úì M√∫ltiples workers ({num_workers}) procesando en paralelo")
    print(f"   ‚úì Threading para concurrencia")
    print(f"   ‚úì TaskQueue thread-safe")
    print(f"   ‚úì Speedup de {actual_speedup:.2f}x")
    print(f"   ‚úì Distribuci√≥n autom√°tica de carga")
    
    print(f"\nüéØ Aplicaciones:")
    print(f"   ‚úì Procesamiento batch de im√°genes")
    print(f"   ‚úì Servidor de procesamiento (m√∫ltiples workers)")
    print(f"   ‚úì Pipeline de datos en paralelo")
    
    print(f"\nüìö Pr√≥ximos pasos:")
    print(f"   ‚Ä¢ Sesi√≥n 4: Redis para cola distribuida")
    print(f"   ‚Ä¢ Sesi√≥n 5: Multiprocessing para mejor paralelismo")
    print(f"   ‚Ä¢ Sesi√≥n 8: Kubernetes auto-scaling")
    
    print("\n" + "=" * 70)


if __name__ == "__main__":
    main()


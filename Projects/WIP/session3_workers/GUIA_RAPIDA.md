# âš¡ GuÃ­a RÃ¡pida - SesiÃ³n 3: Workers

## ğŸ¯ Lo que AprenderÃ¡s Hoy (45 min)

1. **PatrÃ³n Worker**: Arquitectura para procesamiento
2. **Task Queue**: Cola de tareas en memoria
3. **Logging estructurado**: Debugging y monitoreo
4. **EstadÃ­sticas**: MÃ©tricas de performance

---

## ğŸš€ Setup RÃ¡pido

```bash
cd session3_workers
python3 -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

---

## ğŸ“ CÃ³digo Esencial

### 1. Crear Worker Simple (10 min)

```python
from workers import SimpleWorker, TaskQueue
from core import FilterPipeline
from filters import BlurFilter, BrightnessFilter

# 1. Crear pipeline
pipeline = FilterPipeline([
    BlurFilter(radius=3),
    BrightnessFilter(factor=1.3)
])

# 2. Crear cola
queue = TaskQueue()

# 3. AÃ±adir tareas
queue.add_task({
    'image_path': 'images/photo1.jpg',
    'output_path': 'output/photo1.jpg'
})

# 4. Crear worker
worker = SimpleWorker('worker-1', pipeline, queue)

# 5. Procesar tareas
worker.start()  # Procesa automÃ¡ticamente
```

**Resultado:**
- âœ… Worker procesa tareas de la cola
- âœ… Logging automÃ¡tico
- âœ… EstadÃ­sticas de performance

---

### 2. Task Queue (Cola de Tareas) (10 min)

```python
from workers import TaskQueue

queue = TaskQueue()

# AÃ±adir tareas
task_id = queue.add_task({
    'image_path': 'input.jpg',
    'output_path': 'output.jpg'
})

# Obtener tarea
task = queue.get_task('worker-1')

# Marcar como completada
queue.mark_completed(task_id, result={'status': 'success'})

# O marcar como fallida
queue.mark_failed(task_id, error='Archivo no encontrado')

# Ver estadÃ­sticas
stats = queue.get_stats()
print(f"Pendientes: {stats['pending']}")
print(f"Completadas: {stats['completed']}")
```

**CaracterÃ­sticas:**
- âœ… Thread-safe (mÃºltiples workers)
- âœ… Estados: pending â†’ processing â†’ completed/failed
- âœ… EstadÃ­sticas en tiempo real

---

### 3. Logging Estructurado (5 min)

```python
import logging

# El worker ya tiene logging configurado
worker.logger.info("Procesando imagen...")
worker.logger.error("Error: archivo no encontrado")
```

**Output:**
```
2024-11-20 18:30:15,123 - [Worker-1] - INFO - ğŸ“ Procesando tarea task-0001
2024-11-20 18:30:15,456 - [Worker-1] - INFO - âœ… Tarea completada en 1.333s
```

**Â¿Por quÃ© es importante?**
- âœ… Debugging mÃ¡s fÃ¡cil
- âœ… Monitoreo de sistemas distribuidos
- âœ… AnÃ¡lisis de performance

---

### 4. EstadÃ­sticas y Monitoreo (5 min)

```python
# EstadÃ­sticas del worker
stats = worker.get_stats()

print(f"Tareas completadas: {stats['tasks_completed']}")
print(f"Tareas fallidas: {stats['tasks_failed']}")
print(f"Tasa de Ã©xito: {stats['success_rate']:.1%}")
print(f"Tiempo promedio: {stats['total_processing_time'] / stats['tasks_completed']:.3f}s")

# Health check
if worker.is_healthy():
    print("âœ… Worker saludable")
else:
    print("âŒ Worker no saludable")
```

---

## ğŸ¬ Demos Disponibles

### Demo 1: Simple Worker
```bash
python demos/demo_simple_worker.py
```
Muestra worker sÃ­ncrono procesando 3 tareas secuencialmente.

### Demo 2: Async Worker
```bash
python demos/demo_async_worker.py
```
Muestra worker asÃ­ncrono procesando 6 tareas concurrentemente (max 3).

### Demo 3: MÃºltiples Workers
```bash
python demos/demo_multiple_workers.py
```
Muestra 3 workers procesando 12 tareas en paralelo (speedup: 2.44x).

---

## ğŸ¨ Ejercicios PrÃ¡cticos (15 min)

### Ejercicio 1: Multiple Workers (Medio)
Crear 3 workers procesando de la misma cola:

```python
workers = []
for i in range(3):
    worker = SimpleWorker(f'worker-{i}', pipeline, queue)
    workers.append(worker)

# Iniciar todos (usar threading.Thread)
```

### Ejercicio 2: Worker con Retry (Medio)
Modificar SimpleWorker para reintentar tareas fallidas:

```python
def process_task(self, task):
    max_retries = 3
    for attempt in range(max_retries):
        try:
            return self._do_process(task)
        except Exception:
            if attempt == max_retries - 1:
                raise
            time.sleep(2 ** attempt)  # Exponential backoff
```

### Ejercicio 3: Health Check Dashboard (Avanzado)
Crear un monitor que muestre estado de mÃºltiples workers:

```python
def monitor_workers(workers):
    while True:
        for worker in workers:
            status = "âœ…" if worker.is_healthy() else "âŒ"
            stats = worker.get_stats()
            print(f"{status} {worker.worker_id}: {stats['tasks_completed']} completed")
        time.sleep(5)
```

---

## ğŸ“Š Resultados del Demo

**Procesando 3 imÃ¡genes:**

| MÃ©trica | Valor |
|---------|-------|
| **Total de tareas** | 3 |
| **Completadas** | 3 âœ… |
| **Fallidas** | 0 |
| **Tiempo total** | 0.619s |
| **Tiempo promedio** | 0.206s por tarea |
| **Tasa de Ã©xito** | 100.0% |

**Breakdown de tiempos:**
- Carga de imagen: 0.179s (primera vez)
- Pipeline (3 filtros): ~0.138s
- Guardado: ~0.007s

---

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Task Queue    â”‚
â”‚  [Task 1]       â”‚
â”‚  [Task 2]       â”‚
â”‚  [Task 3]       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Simple Worker  â”‚
â”‚  - Get Task     â”‚
â”‚  - Process      â”‚
â”‚  - Mark Done    â”‚
â”‚  - Repeat       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Output Files   â”‚
â”‚  + Statistics   â”‚
â”‚  + Logs         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”— EvoluciÃ³n del Sistema

| Hoy (SesiÃ³n 3) | SesiÃ³n 4 (Redis) | SesiÃ³n 5 (Distribuido) |
|----------------|------------------|------------------------|
| Cola en memoria | Cola en Redis | Workers en mÃºltiples mÃ¡quinas |
| 1 Worker local | N Workers locales | N Workers distribuidos |
| Logging bÃ¡sico | Logging con Redis | Logging centralizado |
| Health check simple | Health checks avanzados | Auto-recovery |

---

## âœ… Checklist de Aprendizaje

Al final de esta sesiÃ³n deberÃ­as poder:

- [ ] Entender el patrÃ³n Worker
- [ ] Crear y usar un TaskQueue
- [ ] Implementar SimpleWorker para procesar tareas
- [ ] Interpretar logs estructurados
- [ ] Leer estadÃ­sticas de workers
- [ ] Verificar health status

---

## ğŸ’¡ Conceptos Clave

### 1. SeparaciÃ³n de Responsabilidades
- **Queue**: Gestiona tareas
- **Worker**: Procesa tareas
- **Pipeline**: Define quÃ© hacer

### 2. Idempotencia
Las tareas deberÃ­an poder reintentarse sin efectos secundarios.

### 3. Graceful Shutdown
Workers terminan la tarea actual antes de detenerse.

### 4. Observabilidad
Logs + EstadÃ­sticas = Visibilidad del sistema

---

## ğŸ¯ PrÃ³xima SesiÃ³n

**SesiÃ³n 4: Redis y Colas Distribuidas**
- Instalar y configurar Redis
- Cola distribuida entre procesos
- SerializaciÃ³n de tareas (JSON/Pickle)
- Workers conectados a Redis

---

## ğŸ¤” Preguntas Frecuentes

### Â¿Por quÃ© no usar multiprocessing?
- SesiÃ³n 3: Entender el patrÃ³n bÃ¡sico
- SesiÃ³n 5: AÃ±adiremos multiprocessing
- SesiÃ³n 8: Kubernetes manejarÃ¡ el paralelismo

### Â¿CÃ³mo escalar horizontalmente?
- **Hoy**: MÃºltiples workers en un proceso
- **SesiÃ³n 5**: MÃºltiples procesos en una mÃ¡quina
- **SesiÃ³n 8**: MÃºltiples pods en Kubernetes

### Â¿QuÃ© pasa si un worker crashea?
- **Hoy**: Tarea se queda en "processing"
- **SesiÃ³n 4**: Redis permite detectar workers muertos
- **SesiÃ³n 9**: Health checks y auto-recovery

---

**Â¡Excelente trabajo! âš™ï¸**

Ahora tienes los fundamentos para construir sistemas de procesamiento distribuido.


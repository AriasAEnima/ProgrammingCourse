"""
AsyncWorker - Worker as√≠ncrono para procesamiento concurrente.

Procesa m√∫ltiples tareas de manera concurrente usando asyncio.
Ideal para tareas I/O bound (lectura/escritura de im√°genes).
"""

import asyncio
import time
import os
from typing import Dict, Any
from PIL import Image
import sys

# Agregar directorio padre al path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from .base_worker import BaseWorker
from .task_queue import TaskQueue
from core import FilterPipeline


class AsyncWorker(BaseWorker):
    """
    Worker as√≠ncrono que procesa im√°genes concurrentemente.
    
    Caracter√≠sticas:
    - Procesa m√∫ltiples tareas concurrentemente (no bloquea en I/O)
    - Usa asyncio para operaciones as√≠ncronas
    - M√°s eficiente que SimpleWorker para I/O-bound tasks
    - Puede manejar mayor throughput
    
    Attributes:
        worker_id (str): ID del worker
        pipeline (FilterPipeline): Pipeline de filtros
        queue (TaskQueue): Cola de tareas
        max_concurrent (int): M√°ximo de tareas concurrentes
        
    Ejemplo:
        pipeline = FilterPipeline([BlurFilter(), BrightnessFilter()])
        queue = TaskQueue()
        
        worker = AsyncWorker('async-worker-1', pipeline, queue, max_concurrent=3)
        asyncio.run(worker.start())  # Procesa hasta 3 tareas a la vez
    """
    
    def __init__(
        self,
        worker_id: str,
        pipeline: FilterPipeline,
        queue: TaskQueue,
        poll_interval: float = 1.0,
        max_concurrent: int = 5
    ):
        """
        Inicializa el worker as√≠ncrono.
        
        Args:
            worker_id: Identificador √∫nico
            pipeline: Pipeline de filtros a aplicar
            queue: Cola de tareas
            poll_interval: Intervalo de polling en segundos
            max_concurrent: M√°ximo de tareas concurrentes
        """
        super().__init__(worker_id)
        
        if not isinstance(pipeline, FilterPipeline):
            raise TypeError(f"pipeline debe ser FilterPipeline, recibido: {type(pipeline)}")
        
        if not isinstance(queue, TaskQueue):
            raise TypeError(f"queue debe ser TaskQueue, recibido: {type(queue)}")
        
        self.pipeline = pipeline
        self.queue = queue
        self.poll_interval = poll_interval
        self.max_concurrent = max_concurrent
        
        # Sem√°foro para limitar concurrencia
        self.semaphore = asyncio.Semaphore(max_concurrent)
    
    async def load_image_async(self, image_path: str) -> Image.Image:
        """
        Carga una imagen de forma as√≠ncrona.
        
        Args:
            image_path: Ruta de la imagen
            
        Returns:
            Image: Imagen cargada
        """
        # PIL no es async nativo, pero podemos ejecutarlo en thread pool
        loop = asyncio.get_event_loop()
        image = await loop.run_in_executor(None, Image.open, image_path)
        return image
    
    async def save_image_async(self, image: Image.Image, output_path: str):
        """
        Guarda una imagen de forma as√≠ncrona.
        
        Args:
            image: Imagen a guardar
            output_path: Ruta de salida
        """
        # Crear directorio si no existe
        output_dir = os.path.dirname(output_path)
        if output_dir:
            os.makedirs(output_dir, exist_ok=True)
        
        # Guardar en thread pool
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(
            None,
            lambda: image.save(output_path, quality=95)
        )
    
    def process_task(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """
        M√©todo s√≠ncrono requerido por BaseWorker.
        
        Este m√©todo NO se usa en AsyncWorker.
        Usar process_task_async() en su lugar.
        """
        raise NotImplementedError(
            "AsyncWorker usa process_task_async(). "
            "No uses process_task() directamente."
        )
    
    async def process_task_async(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """
        Procesa una tarea de forma as√≠ncrona.
        
        Args:
            task: Diccionario con informaci√≥n de la tarea
            
        Returns:
            Dict: Resultado del procesamiento
        """
        task_id = task.get('id', 'unknown')
        image_path = task.get('image_path')
        output_path = task.get('output_path')
        
        self.logger.info(f"üìù [Async] Procesando tarea {task_id}")
        self.logger.debug(f"   Entrada: {image_path}")
        self.logger.debug(f"   Salida: {output_path}")
        
        start_time = time.time()
        
        try:
            # 1. Cargar imagen (async)
            load_start = time.time()
            image = await self.load_image_async(image_path)
            load_time = time.time() - load_start
            self.logger.debug(f"   Imagen cargada en {load_time:.3f}s")
            
            # 2. Aplicar pipeline (en thread pool, no es CPU-bound cr√≠tico)
            pipeline_start = time.time()
            loop = asyncio.get_event_loop()
            result_image, pipeline_stats = await loop.run_in_executor(
                None, 
                self.pipeline.apply, 
                image
            )
            pipeline_time = time.time() - pipeline_start
            
            if result_image is None:
                raise ValueError("Pipeline retorn√≥ None")
            
            # 3. Guardar resultado (async)
            save_start = time.time()
            await self.save_image_async(result_image, output_path)
            save_time = time.time() - save_start
            
            # 4. Calcular tiempo total
            total_time = time.time() - start_time
            
            # 5. Construir resultado
            result = {
                'task_id': task_id,
                'worker_id': self.worker_id,
                'status': 'success',
                'input_path': image_path,
                'output_path': output_path,
                'image_size': image.size,
                'times': {
                    'load': load_time,
                    'pipeline': pipeline_time,
                    'save': save_time,
                    'total': total_time
                },
                'pipeline_stats': pipeline_stats
            }
            
            # 6. Actualizar estad√≠sticas
            self.stats['tasks_completed'] += 1
            self.stats['total_processing_time'] += total_time
            self.stats['last_task_at'] = time.time()
            
            self.logger.info(f"‚úÖ [Async] Tarea {task_id} completada en {total_time:.3f}s")
            
            return result
            
        except Exception as e:
            error_msg = str(e)
            self.logger.error(f"‚ùå [Async] Tarea {task_id} fall√≥: {error_msg}")
            self.stats['tasks_failed'] += 1
            raise
    
    async def worker_loop(self):
        """
        Loop principal del worker que procesa tareas.
        """
        consecutive_empty_polls = 0
        
        while self.is_running:
            # Obtener pr√≥xima tarea
            task = self.queue.get_task(self.worker_id)
            
            if task is None:
                consecutive_empty_polls += 1
                
                if consecutive_empty_polls == 1:
                    self.logger.debug("üí§ No hay tareas disponibles")
                
                await asyncio.sleep(self.poll_interval)
                continue
            
            # Reset contador
            consecutive_empty_polls = 0
            
            # Procesar tarea con sem√°foro (limitar concurrencia)
            async with self.semaphore:
                task_id = task.get('id', 'unknown')
                self.current_task = task
                
                try:
                    result = await self.process_task_async(task)
                    self.queue.mark_completed(task_id, result)
                    
                except Exception as e:
                    error_msg = str(e)
                    self.queue.mark_failed(task_id, error_msg)
                    
                finally:
                    self.current_task = None
    
    async def start(self):
        """
        Inicia el worker as√≠ncrono.
        
        Crea m√∫ltiples coroutines para procesar tareas concurrentemente.
        """
        super().start()  # Llama a BaseWorker.start()
        
        self.logger.info(f"üîç [Async] Worker escuchando cola: {self.queue}")
        self.logger.info(f"üé® Pipeline: {self.pipeline}")
        self.logger.info(f"‚ö° Max concurrencia: {self.max_concurrent} tareas")
        
        try:
            await self.worker_loop()
            
        except asyncio.CancelledError:
            self.logger.info("‚ö†Ô∏è  Worker cancelado")
            
        except KeyboardInterrupt:
            self.logger.info("‚ö†Ô∏è  Interrupci√≥n de teclado")
            
        finally:
            self.stop()
    
    def __repr__(self) -> str:
        """Representaci√≥n en string."""
        status = "running" if self.is_running else "stopped"
        return (
            f"AsyncWorker("
            f"id={self.worker_id}, "
            f"status={status}, "
            f"max_concurrent={self.max_concurrent}, "
            f"completed={self.stats['tasks_completed']})"
        )


# Ejemplo de uso
if __name__ == "__main__":
    print("‚ö° Ejemplo de uso de AsyncWorker")
    print("=" * 70)
    
    print("""
    El AsyncWorker procesa tareas de manera as√≠ncrona (concurrente).
    
    Ventajas sobre SimpleWorker:
    - ‚úì No bloquea en I/O (carga/guardado de im√°genes)
    - ‚úì Puede procesar m√∫ltiples tareas a la vez
    - ‚úì Mayor throughput para tareas I/O-bound
    - ‚úì Mejor uso de recursos
    
    Ejemplo de c√≥digo:
    """)
    
    print("""
    import asyncio
    from workers import AsyncWorker, TaskQueue
    from core import FilterPipeline
    from filters import BlurFilter, BrightnessFilter
    
    # Crear pipeline
    pipeline = FilterPipeline([
        BlurFilter(radius=3),
        BrightnessFilter(factor=1.3)
    ])
    
    # Crear cola con m√∫ltiples tareas
    queue = TaskQueue()
    for i in range(10):
        queue.add_task({
            'image_path': f'images/photo{i}.jpg',
            'output_path': f'output/photo{i}.jpg'
        })
    
    # Crear worker as√≠ncrono (procesa hasta 5 a la vez)
    worker = AsyncWorker('async-worker-1', pipeline, queue, max_concurrent=5)
    
    # Iniciar (async)
    asyncio.run(worker.start())
    """)
    
    print("\nüéØ Cu√°ndo usar AsyncWorker:")
    print("""
    ‚úì Muchas im√°genes peque√±as (I/O-bound)
    ‚úì Necesitas alto throughput
    ‚úì Tienes m√∫ltiples CPUs disponibles
    ‚úì Procesamiento en red o servicios remotos
    
    ‚ö†Ô∏è  Cu√°ndo NO usar AsyncWorker:
    ‚úó Pocas im√°genes grandes (SimpleWorker es suficiente)
    ‚úó Pipeline es muy CPU-intensive
    ‚úó Simplicidad es m√°s importante que performance
    """)


# ğŸ” SesiÃ³n 5: Health Checks, Auto-Recovery y Monitoring

## âœ… Estado: COMPLETADA Y VERIFICADA

**Todos los demos probados y funcionando al 100%** âœ¨

## âš ï¸ Setup RÃ¡pido

### 1. Iniciar Redis

```bash
# Abre Docker Desktop primero, luego:
docker run -d -p 6379:6379 --name redis redis:7-alpine

# Verificar
docker exec redis redis-cli ping  # Debe responder: PONG
```

### 2. Instalar dependencias

```bash
cd session5_monitoring
python3 -m venv venv

# Windows:
venv\Scripts\activate

# macOS/Linux:
source venv/bin/activate

pip install -r requirements.txt
```

### 3. Ejecutar demos

```bash
python demos/demo_worker_registry.py      # Demo 1: Worker Registry
python demos/demo_auto_recovery.py        # Demo 2: Auto-Recovery y DLQ
python demos/demo_monitored_system.py     # Demo 3: Sistema completo
```

**Detener Redis cuando termines:**
```bash
docker stop redis && docker rm redis
```

---

## ğŸ“‚ Estructura del Proyecto

```
session5_monitoring/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ filters/                      # Filtros (de SesiÃ³n 2)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_filter.py
â”‚   â”œâ”€â”€ blur_filter.py
â”‚   â”œâ”€â”€ brightness_filter.py
â”‚   â”œâ”€â”€ edges_filter.py
â”‚   â””â”€â”€ grayscale_filter.py
â”‚
â”œâ”€â”€ core/                         # Pipeline (de SesiÃ³n 2)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ filter_pipeline.py
â”‚   â”œâ”€â”€ filter_factory.py
â”‚   â””â”€â”€ batch_processor.py
â”‚
â”œâ”€â”€ workers/                      # ğŸ†• Workers con Monitoring
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ worker_registry.py        # ğŸ†• Registro de workers
â”‚   â”œâ”€â”€ redis_task_queue_v2.py    # ğŸ†• Cola con auto-recovery
â”‚   â””â”€â”€ monitored_redis_worker.py # ğŸ†• Worker con heartbeats
â”‚
â”œâ”€â”€ demos/
â”‚   â”œâ”€â”€ demo_worker_registry.py         # Demo 1: Registry
â”‚   â”œâ”€â”€ demo_auto_recovery.py           # Demo 2: Reintentos y DLQ
â”‚   â””â”€â”€ demo_monitored_system.py        # Demo 3: Sistema completo
â”‚
â”œâ”€â”€ images/
â”‚   â””â”€â”€ sample.jpg
â”‚
â””â”€â”€ output/
```

---

## ğŸ†• Â¿QuÃ© hay de nuevo en SesiÃ³n 5?

### ComparaciÃ³n con SesiÃ³n 4

| CaracterÃ­stica | SesiÃ³n 4 (Redis BÃ¡sico) | SesiÃ³n 5 (Monitoring) |
|----------------|-------------------------|----------------------|
| **Worker Registry** | âŒ No | âœ… Registry centralizado |
| **Heartbeats** | âŒ No | âœ… Workers reportan salud |
| **Auto-recovery** | âŒ Manual | âœ… Reintentos automÃ¡ticos |
| **Dead Letter Queue** | âŒ No | âœ… Para tareas irrecuperables |
| **Graceful Shutdown** | âš ï¸ BÃ¡sico | âœ… Signal handlers |
| **Stuck Task Recovery** | âŒ No | âœ… Detecta tareas atascadas |

---

## ğŸ§© Componentes Principales

### 1. WorkerRegistry

**PropÃ³sito:** Registro centralizado de workers activos en Redis.

**Funcionalidades:**
- Registrar/des-registrar workers
- Enviar heartbeats periÃ³dicos
- Detectar workers muertos (sin heartbeat)
- Limpiar workers muertos automÃ¡ticamente

**Uso bÃ¡sico:**

```python
from workers import WorkerRegistry

registry = WorkerRegistry(heartbeat_timeout=30)

# Registrar worker
registry.register_worker("worker-1", metadata={"hostname": "server-1"})

# Enviar heartbeat
registry.send_heartbeat("worker-1")

# Ver workers activos
active = registry.get_active_workers()
for worker in active:
    print(f"{worker['worker_id']}: alive={worker['is_alive']}")

# Limpiar workers muertos
registry.cleanup_dead_workers()
```

**Almacenamiento en Redis:**
```
worker_registry:workers:worker-1
  worker_id: worker-1
  registered_at: 2024-01-15T10:30:00
  last_heartbeat: 1705318200.5
  status: active
  hostname: server-1
```

---

### 2. RedisTaskQueueV2

**PropÃ³sito:** Cola de tareas con auto-recovery y Dead Letter Queue.

**Mejoras respecto a SesiÃ³n 4:**
- âœ… **Reintentos automÃ¡ticos**: Tareas fallidas se reintentan hasta `max_retries`
- âœ… **Dead Letter Queue (DLQ)**: Tareas con demasiados fallos van a DLQ
- âœ… **Contador de reintentos**: Cada tarea sabe cuÃ¡ntas veces ha fallado
- âœ… **RecuperaciÃ³n de tareas atascadas**: Detecta tareas sin progreso por timeout

**Estados de tareas:**

```
pending â†’ processing â†’ completed  âœ…
    â†“                    â†“
  failed (retry)       dead (DLQ) ğŸ’€
    â†“
  pending (retry)
```

**Uso bÃ¡sico:**

```python
from workers import RedisTaskQueueV2

queue = RedisTaskQueueV2(max_retries=3)

# Agregar tarea
task_id = queue.add_task({
    "input_path": "images/sample.jpg",
    "output_path": "output/result.jpg"
})

# Worker procesa tarea
task = queue.get_task("worker-1")

# Si falla, se reintenta automÃ¡ticamente
queue.mark_failed(task_id, "Error de red")  # retry_count++

# DespuÃ©s de 3 fallos â†’ DLQ
dlq_tasks = queue.get_dead_letter_tasks()

# Recuperar tareas atascadas (sin progreso por 5min)
recovered = queue.recover_stuck_tasks()
```

**Almacenamiento en Redis:**
```
# Cola de tareas
image_processing_v2:pending       â†’ [task-1, task-2]
image_processing_v2:processing    â†’ [task-3]
image_processing_v2:completed     â†’ [task-4, task-5]
image_processing_v2:dead_letter   â†’ [task-6]  ğŸ’€

# Metadata de tarea
task:task-1
  task_id: task-1
  data: {"input_path": "...", ...}
  status: pending
  retry_count: 2
  last_error: "Connection timeout"
  created_at: 2024-01-15T10:30:00
```

---

### 3. MonitoredRedisWorker

**PropÃ³sito:** Worker que procesa tareas y reporta su salud.

**CaracterÃ­sticas:**
- âœ… Se registra en `WorkerRegistry` al iniciar
- âœ… EnvÃ­a heartbeats periÃ³dicos (cada 10s por defecto)
- âœ… Maneja seÃ±ales de interrupciÃ³n (Ctrl+C, SIGTERM)
- âœ… Graceful shutdown (se des-registra antes de cerrar)
- âœ… Logging estructurado

**Uso bÃ¡sico:**

```python
from workers import MonitoredRedisWorker

worker = MonitoredRedisWorker(
    worker_id="worker-1",
    heartbeat_interval=10  # Heartbeat cada 10s
)

worker.start()  # Bloquea hasta que se detenga
```

**Flujo del worker:**

```
1. Registrar en WorkerRegistry
2. Loop:
   a. Enviar heartbeat si es necesario
   b. Obtener tarea de la cola (timeout=5s)
   c. Procesar tarea
   d. Marcar como completed/failed
3. Graceful shutdown:
   a. Des-registrar del registry
   b. Mostrar estadÃ­sticas
```

---

## ğŸ¯ Demos Explicados

### Demo 1: Worker Registry

**QuÃ© hace:**
- Registra 3 workers
- EnvÃ­a heartbeats para 2 de ellos
- Detecta que 1 worker muriÃ³ (sin heartbeat)
- Limpia workers muertos

**Ejecutar:**
```bash
python demos/demo_worker_registry.py
```

**Salida esperada:**
```
âœ… Worker registrado: worker-1
âœ… Worker registrado: worker-2
âœ… Worker registrado: worker-3
ğŸ’“ Heartbeat enviado (worker-1, worker-2)
ğŸ’€ Detectando workers muertos...
  - worker-3: muerto hace 12s
ğŸ§¹ Limpiados 1 worker(s) muerto(s)
```

---

### Demo 2: Auto-Recovery

**QuÃ© hace:**
- Agrega 3 tareas a la cola
- Simula que una tarea falla 4 veces
- DespuÃ©s de 3 reintentos â†’ DLQ
- Reintenta manualmente desde DLQ
- Completa todas las tareas

**Ejecutar:**
```bash
python demos/demo_auto_recovery.py
```

**Salida esperada:**
```
ğŸ“¥ Agregando 3 tareas...
ğŸ’¥ Simulando fallos en task1...
  Intento 1 (retry=0)
  âš ï¸  Tarea fallida (reintento 1/3)
  Intento 2 (retry=1)
  âš ï¸  Tarea fallida (reintento 2/3)
  Intento 3 (retry=2)
  âš ï¸  Tarea fallida (reintento 3/3)
  Intento 4 (retry=3)
  ğŸ’€ Tarea en DLQ (reintentos agotados)

ğŸ“Š EstadÃ­sticas:
  dead_letter: 1 ğŸ’€

ğŸ”„ Reintentando tarea desde DLQ...
âœ… Completadas: 3
```

---

### Demo 3: Sistema Completo con Monitoring

**QuÃ© hace:**
- Agrega 10 tareas a la cola
- Lanza 3 workers monitoreados (multiprocessing)
- Monitorea progreso en tiempo real
- Muestra workers activos y heartbeats
- Detiene workers limpiamente

**Ejecutar:**
```bash
python demos/demo_monitored_system.py
```

**Salida esperada:**
```
ğŸ“¥ Agregando 10 tareas a la cola...
ğŸš€ Lanzando 3 workers monitoreados...

ğŸ“Š Monitoreando progreso...
â±ï¸  0s | Workers activos: 3 | Pending: 10 | Processing: 2 | Completed: 0
   - monitored-worker-1: heartbeat hace 2.1s
   - monitored-worker-2: heartbeat hace 1.8s
   - monitored-worker-3: heartbeat hace 1.5s

â±ï¸  3s | Workers activos: 3 | Pending: 5 | Processing: 3 | Completed: 2
   - monitored-worker-1: heartbeat hace 0.3s
   - monitored-worker-2: heartbeat hace 0.5s
   - monitored-worker-3: heartbeat hace 0.8s

âœ… Todas las tareas completadas!

ğŸ“Š EstadÃ­sticas finales:
  Completadas: 10
  Tiempo total: 12.45s
```

---

## ğŸ’¡ Conceptos Clave

### 1. Heartbeat

**Â¿QuÃ© es?**
SeÃ±al periÃ³dica que un worker envÃ­a para indicar que estÃ¡ vivo.

**Â¿Por quÃ© es importante?**
- Detectar workers que crashearon
- Saber cuÃ¡ntos workers estÃ¡n activos
- Tomar decisiones de escalado

**ImplementaciÃ³n:**
```python
# Worker envÃ­a heartbeat cada 10s
while running:
    if time.time() - last_heartbeat >= heartbeat_interval:
        registry.send_heartbeat(worker_id)
        last_heartbeat = time.time()
```

---

### 2. Dead Letter Queue (DLQ)

**Â¿QuÃ© es?**
Cola especial para tareas que fallaron demasiadas veces.

**Â¿Por quÃ© es Ãºtil?**
- Evita reintentar indefinidamente
- Permite inspecciÃ³n manual de fallos
- Libera la cola principal de tareas problemÃ¡ticas

**CuÃ¡ndo usar:**
- Errores de validaciÃ³n (input invÃ¡lido)
- Recursos no encontrados
- Errores de lÃ³gica (no de infraestructura)

**CuÃ¡ndo NO usar:**
- Errores temporales de red
- Timeouts ocasionales
- Falta temporal de recursos

---

### 3. Auto-Recovery

**Â¿QuÃ© es?**
Mecanismo para reintentar tareas fallidas automÃ¡ticamente.

**Estrategias:**
- **Reintentos inmediatos**: Volver a encolar enseguida
- **Exponential backoff**: Esperar mÃ¡s tiempo entre reintentos
- **Dead Letter Queue**: LÃ­mite de reintentos

**ImplementaciÃ³n en esta sesiÃ³n:**
```python
def mark_failed(task_id, error):
    retry_count += 1
    
    if retry_count < max_retries:
        # Reintentar: volver a pending
        redis.rpush(pending_key, task_id)
    else:
        # Dead Letter Queue
        redis.rpush(dead_letter_key, task_id)
```

---

### 4. Graceful Shutdown

**Â¿QuÃ© es?**
Cerrar un worker limpiamente, terminando tareas en progreso.

**Pasos:**
1. Recibir seÃ±al de interrupciÃ³n (SIGINT, SIGTERM)
2. Detener de aceptar nuevas tareas
3. Terminar tarea actual
4. Des-registrar del registry
5. Cerrar conexiones
6. Salir

**ImplementaciÃ³n:**
```python
signal.signal(signal.SIGINT, self._signal_handler)

def _signal_handler(self, signum, frame):
    self.running = False  # Detener loop

def _shutdown(self):
    registry.unregister_worker(self.worker_id)
    # Limpiar recursos...
```

---

### 5. Stuck Task Recovery

**Â¿QuÃ© es?**
Detectar tareas que llevan demasiado tiempo en "processing" sin completarse.

**Causas comunes:**
- Worker crasheÃ³ sin marcar la tarea como fallida
- Worker perdiÃ³ conexiÃ³n a Redis
- Worker estÃ¡ colgado (deadlock, loop infinito)

**SoluciÃ³n:**
```python
def recover_stuck_tasks(self):
    for task_id in processing_queue:
        if task["started_at"] + timeout < now:
            # Tarea atascada: mover a pending
            mark_failed(task_id, "Timeout")
```

---

## ğŸ§¹ Limpieza y Mantenimiento

### Limpiar todas las tareas

```bash
docker exec redis redis-cli FLUSHDB
```

O desde Python:
```python
queue = RedisTaskQueueV2()
queue.clear()

registry = WorkerRegistry()
registry.clear()
```

### Inspeccionar Dead Letter Queue

```python
from workers import RedisTaskQueueV2

queue = RedisTaskQueueV2()
dlq_tasks = queue.get_dead_letter_tasks()

for task_id in dlq_tasks:
    print(f"Tarea muerta: {task_id}")
```

### Reintentar tareas de DLQ

```python
# Reintentar una tarea especÃ­fica
queue.retry_dead_letter_task("task-123")

# O reintentar todas
for task_id in queue.get_dead_letter_tasks():
    queue.retry_dead_letter_task(task_id)
```

### Verificar workers activos

```python
from workers import WorkerRegistry

registry = WorkerRegistry()
active = registry.get_active_workers()

for worker in active:
    print(f"{worker['worker_id']}: "
          f"heartbeat hace {worker['time_since_heartbeat']}s")
```

---

## ğŸ”§ Comandos Ãštiles de Redis

```bash
# Ver workers registrados
docker exec redis redis-cli KEYS "worker_registry:*"

# Ver info de un worker
docker exec redis redis-cli HGETALL "worker_registry:workers:worker-1"

# Ver tareas en DLQ
docker exec redis redis-cli LRANGE "image_processing_v2:dead_letter" 0 -1

# Ver info de una tarea
docker exec redis redis-cli HGETALL "task:task-123"

# Limpiar todo
docker exec redis redis-cli FLUSHDB
```

---

## ğŸ› Troubleshooting

### Workers no se registran

**Problema:** Workers se lanzan pero no aparecen en el registry.

**SoluciÃ³n:**
1. Verificar que Redis estÃ© corriendo:
   ```bash
   docker exec redis redis-cli ping
   ```

2. Verificar que el worker llama a `register_worker`:
   ```python
   registry.register_worker(worker_id)
   ```

---

### Workers aparecen como "muertos"

**Problema:** Workers activos aparecen como muertos en el registry.

**Causas:**
- Heartbeat interval muy largo
- Heartbeat timeout muy corto
- Worker no estÃ¡ enviando heartbeats

**SoluciÃ³n:**
```python
# Aumentar timeout o reducir interval
registry = WorkerRegistry(heartbeat_timeout=60)
worker = MonitoredRedisWorker(heartbeat_interval=10)
```

---

### Tareas van a DLQ demasiado rÃ¡pido

**Problema:** Tareas fallidas van directo a DLQ sin reintentos.

**SoluciÃ³n:**
```python
# Aumentar max_retries
queue = RedisTaskQueueV2(max_retries=5)
```

---

### Workers no se detienen con Ctrl+C

**Problema:** Ctrl+C no detiene el worker limpiamente.

**SoluciÃ³n:**
Verificar que los signal handlers estÃ©n configurados:
```python
signal.signal(signal.SIGINT, self._signal_handler)
signal.signal(signal.SIGTERM, self._signal_handler)
```

---

## ğŸ“Š ComparaciÃ³n: SesiÃ³n 4 vs SesiÃ³n 5

### SesiÃ³n 4: Redis BÃ¡sico

```python
# Workers independientes, sin coordinaciÃ³n
worker = RedisWorker("worker-1")
worker.start()

# No hay forma de saber:
# - Â¿CuÃ¡ntos workers estÃ¡n vivos?
# - Â¿QuÃ© worker estÃ¡ procesando quÃ© tarea?
# - Â¿AlgÃºn worker crasheÃ³?
```

### SesiÃ³n 5: Monitoring Completo

```python
# Workers monitoreados, con coordinaciÃ³n
worker = MonitoredRedisWorker("worker-1")
worker.start()

# Ahora puedes:
# - Ver workers activos: registry.get_active_workers()
# - Detectar crashes: registry.get_dead_workers()
# - Rastrear tareas: queue.get_stats()
# - Reintentar fallos: automÃ¡tico
# - Inspeccionar DLQ: queue.get_dead_letter_tasks()
```

---

## ğŸ“ Ejercicios Propuestos

### Ejercicio 1: Exponential Backoff

Modificar `RedisTaskQueueV2` para que los reintentos usen exponential backoff:
- Reintento 1: inmediato
- Reintento 2: esperar 5s
- Reintento 3: esperar 10s
- Reintento 4: esperar 20s

**Pista:** Usar `time.sleep()` o un campo `retry_after` en la tarea.

---

### Ejercicio 2: Dashboard de Monitoring

Crear un script `dashboard.py` que muestre en tiempo real:
- Workers activos vs muertos
- Tareas pending/processing/completed/DLQ
- Throughput (tareas/segundo)
- Tasa de fallos

**Pista:** Usar un loop con `time.sleep(1)` y `\r` para actualizar la misma lÃ­nea.

---

### Ejercicio 3: Alertas

Implementar sistema de alertas que detecte:
- Todos los workers estÃ¡n muertos
- DLQ tiene mÃ¡s de 10 tareas
- Tasa de fallos > 50%

**Pista:** Crear clase `AlertManager` que revise mÃ©tricas periÃ³dicamente.

---

## ğŸš€ PrÃ³xima SesiÃ³n

**SesiÃ³n 6: Docker y ContainerizaciÃ³n**

AprenderÃ¡s a:
- Crear Dockerfile para workers
- Docker Compose para orquestar mÃºltiples servicios
- Networking entre containers
- VolÃºmenes para persistencia

---

## ğŸ“š Recursos Adicionales

- **Redis Commands:** https://redis.io/commands
- **Signal Handling en Python:** https://docs.python.org/3/library/signal.html
- **Multiprocessing:** https://docs.python.org/3/library/multiprocessing.html
- **Dead Letter Queue Pattern:** https://en.wikipedia.org/wiki/Dead_letter_queue

---

## âœ… Resumen de la SesiÃ³n

**Aprendiste:**
- âœ… Implementar Worker Registry para rastrear workers activos
- âœ… Enviar heartbeats para health checks
- âœ… Auto-recovery con reintentos automÃ¡ticos
- âœ… Dead Letter Queue para tareas irrecuperables
- âœ… Graceful shutdown con signal handlers
- âœ… Detectar y recuperar tareas atascadas

**Habilidades adquiridas:**
- DiseÃ±ar sistemas distribuidos resilientes
- Implementar health checks y monitoring
- Manejar fallos de forma elegante
- Debugging de sistemas distribuidos

**Siguiente nivel:**
En la SesiÃ³n 6 empaquetaremos todo esto en containers Docker, preparando el camino para Kubernetes. ğŸ³

---

## ğŸ§ª VerificaciÃ³n de Funcionamiento

### Resultados de Tests (Ãšltima VerificaciÃ³n)

**Demo 1: Worker Registry**
- âœ… Registro de 3 workers exitoso
- âœ… Heartbeats funcionando correctamente
- âœ… DetecciÃ³n de workers muertos (timeout 10s)
- âœ… Limpieza automÃ¡tica funcionando
- âœ… Des-registro correcto

**Demo 2: Auto-Recovery y DLQ**
- âœ… Reintentos automÃ¡ticos (max 3)
- âœ… Tareas movidas a DLQ despuÃ©s de 3 fallos
- âœ… Re-intento desde DLQ funcional
- âœ… EstadÃ­sticas correctas

**Demo 3: Sistema Completo**
- âœ… 10 imÃ¡genes procesadas exitosamente
- âœ… 3 workers en paralelo funcionando
- âœ… Heartbeats enviados periÃ³dicamente
- âœ… Graceful shutdown operativo
- âœ… 7 archivos de salida generados con diferentes filtros

**Performance:**
- Procesamiento de 10 tareas: < 1 segundo
- Workers coordinados correctamente
- Sin tareas perdidas o atascadas


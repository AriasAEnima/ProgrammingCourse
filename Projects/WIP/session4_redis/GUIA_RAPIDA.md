# âš¡ GuÃ­a RÃ¡pida - SesiÃ³n 4: Redis y Colas Distribuidas

## ğŸ¯ Lo que AprenderÃ¡n Hoy (45 min)

1. **Redis como cola distribuida**: Persistencia y distribuciÃ³n
2. **RedisTaskQueue**: Cola de tareas con operaciones atÃ³micas
3. **RedisWorker**: Workers procesando desde Redis
4. **Multiprocessing**: Paralelismo real (sin GIL)
5. **Monitoreo**: redis-cli para inspeccionar cola

---

## ğŸš€ Setup RÃ¡pido

### Antes de la clase:

```bash
# 1. Instalar Redis
brew install redis      # macOS
# O Docker:
docker run -d -p 6379:6379 --name redis redis:7-alpine

# 2. Iniciar Redis
redis-server &

# 3. Verificar
redis-cli ping  # Debe responder "PONG"

# 4. Setup proyecto
cd session4_redis
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

---

## ğŸ“ CÃ³digo Esencial

### 1. RedisTaskQueue BÃ¡sico (10 min)

```python
from workers import RedisTaskQueue

# Conectar a Redis
queue = RedisTaskQueue(host='localhost', port=6379)

# AÃ±adir tareas
task_id = queue.add_task({
    'image_path': 'input.jpg',
    'output_path': 'output.jpg'
})

# Worker obtiene tarea (atÃ³mico con RPOPLPUSH)
task = queue.get_task('worker-1')

# Procesar...

# Marcar como completada
queue.mark_completed(task['id'], {'status': 'success'})

# EstadÃ­sticas
print(queue.get_stats())
```

**Conceptos clave:**
- âœ… OperaciÃ³n atÃ³mica (RPOPLPUSH)
- âœ… Persistencia en Redis
- âœ… Estados: pending â†’ processing â†’ completed/failed

---

### 2. RedisWorker (10 min)

```python
from workers import RedisWorker, RedisTaskQueue
from core import FilterPipeline
from filters import BlurFilter

queue = RedisTaskQueue(host='localhost')
pipeline = FilterPipeline([BlurFilter()])

worker = RedisWorker('worker-1', pipeline, queue)
worker.start()  # Procesa hasta que la cola estÃ© vacÃ­a
```

**Similar a SimpleWorker pero:**
- Conecta a Redis en lugar de TaskQueue en memoria
- Puede correr en diferentes mÃ¡quinas
- Resultados persistentes

---

### 3. MÃºltiples Workers Distribuidos (10 min)

```python
import multiprocessing

def worker_process(worker_id):
    queue = RedisTaskQueue()
    pipeline = FilterPipeline([BlurFilter()])
    worker = RedisWorker(worker_id, pipeline, queue)
    worker.start()

# Lanzar 3 workers en procesos separados
processes = []
for i in range(3):
    p = multiprocessing.Process(
        target=worker_process,
        args=(f'worker-{i}',)
    )
    p.start()
    processes.append(p)

# Esperar
for p in processes:
    p.join()
```

**Por quÃ© multiprocessing:**
- âœ… Evita Python GIL
- âœ… Verdadero paralelismo
- âœ… Simula workers en mÃ¡quinas diferentes

---

## ğŸ¬ Demos

### Demo 1: Redis BÃ¡sico (15 min)

```bash
python demos/demo_redis_basic.py
```

**QuÃ© mostrar:**
1. ConexiÃ³n a Redis
2. AÃ±adir 3 tareas a Redis
3. Worker procesando tareas
4. Persistencia: tareas y resultados en Redis
5. InspecciÃ³n con redis-cli

**Comandos de redis-cli para mostrar:**
```bash
# Ver todas las keys
redis-cli KEYS "*"

# Ver tareas pendientes
redis-cli LRANGE image_processing:pending 0 -1

# Ver tareas completadas
redis-cli LRANGE image_processing:completed 0 -1

# Ver detalles de tarea
redis-cli HGETALL task:TASK_ID
```

### Demo 2: Workers Distribuidos (15 min)

```bash
python demos/demo_distributed_workers.py
```

**QuÃ© mostrar:**
1. 15 tareas aÃ±adidas a Redis
2. 3 workers en procesos separados
3. DistribuciÃ³n automÃ¡tica de carga
4. Speedup ~3x (vs 1x secuencial)
5. Resultados agregados en Redis

**Puntos clave:**
- Cada worker es un proceso separado (simula distribuciÃ³n)
- Redis coordina todo automÃ¡ticamente
- Sin GIL â†’ mejor paralelismo que threading

---

## ğŸ’¬ Puntos Clave para Discutir

### 1. Â¿Por quÃ© Redis?

**Ventajas sobre cola en memoria:**
- âœ“ Persistencia (sobrevive reinicios)
- âœ“ DistribuciÃ³n (workers en diferentes mÃ¡quinas)
- âœ“ AtÃ³mica (RPOPLPUSH es thread-safe y process-safe)
- âœ“ Escalable (millones de tareas)
- âœ“ Observable (redis-cli para inspeccionar)

**Desventajas:**
- âœ— Dependencia externa (Redis debe estar corriendo)
- âœ— Latencia de red (microsegundos vs nanosegundos)
- âœ— MÃ¡s complejo que cola en memoria

### 2. RPOPLPUSH: La OperaciÃ³n Clave

```redis
RPOPLPUSH source destination
```

- **AtÃ³mica**: Remueve de `source` y aÃ±ade a `destination` en una sola operaciÃ³n
- **Segura**: Solo un worker obtiene cada tarea
- **Eficiente**: O(1)

Ejemplo:
```
pending: [task1, task2, task3]
processing: {}

Worker hace: RPOPLPUSH pending processing

pending: [task1, task2]
processing: {task3: worker-1}
```

### 3. Threading vs Multiprocessing

| Aspecto | Threading (SesiÃ³n 3) | Multiprocessing (SesiÃ³n 4) |
|---------|---------------------|----------------------------|
| **GIL** | Limitado por GIL | Sin GIL |
| **Memoria** | Compartida | Separada |
| **Performance (I/O)** | Buena | Excelente |
| **Performance (CPU)** | Limitada | Excelente |
| **Complejidad** | Baja | Media |

**Para procesamiento de imÃ¡genes (CPU-bound):**
- Multiprocessing es mejor âœ…

### 4. Estados de Tareas

```
pending â†’ processing â†’ completed
                    â†’ failed
```

- **pending**: En espera de worker
- **processing**: Worker la estÃ¡ procesando
- **completed**: Exitosa
- **failed**: Error durante procesamiento

### 5. Producer-Consumer Pattern

```
Producer(s)          Redis           Consumer(s)
    â”‚                  â”‚                  â”‚
    â”œâ”€â”€ add_task() â”€â”€â–º â”‚                  â”‚
    â”œâ”€â”€ add_task() â”€â”€â–º â”‚ â—„â”€â”€ get_task() â”€â”€â”¤
    â”‚                  â”‚ â—„â”€â”€ get_task() â”€â”€â”¤
    â”‚                  â”‚ â—„â”€â”€ get_task() â”€â”€â”¤
    â”‚                  â”‚                  â”‚
```

- Desacoplamiento total
- Producers y consumers no se conocen
- FÃ¡cil de escalar (aÃ±adir mÃ¡s de cada tipo)

---

## ğŸ“Š Resultados Esperados del Demo

### Demo 1 (Basic):

```
ğŸ“Š Cola: pending=0, processing=0, completed=3, failed=0
âš™ï¸  Worker: 3 tareas completadas en ~0.6s
ğŸ“ Archivos: redis_blur.jpg, redis_bright.jpg, redis_combined.jpg
```

### Demo 2 (Distributed):

```
ğŸ“Š Cola: completed=15, failed=0
âš™ï¸  Workers: 3 workers en procesos separados
âš¡ Performance: Speedup ~3x, Eficiencia ~95%
ğŸ‘¥ DistribuciÃ³n: worker-1: 5, worker-2: 5, worker-3: 5
```

---

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            API / Producer                â”‚
â”‚         (AÃ±ade tareas a Redis)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             Redis Server                 â”‚
â”‚                                          â”‚
â”‚  pending:    [task1, task2, task3]       â”‚
â”‚  processing: {task4: worker-1}           â”‚
â”‚  completed:  [task5, task6]              â”‚
â”‚                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚            â”‚          â”‚
           â–¼            â–¼          â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Worker 1 â”‚ â”‚ Worker 2 â”‚ â”‚ Worker 3 â”‚
    â”‚  (CPU 1) â”‚ â”‚  (CPU 2) â”‚ â”‚  (CPU 3) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚            â”‚          â”‚
         â–¼            â–¼          â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚        ImÃ¡genes Procesadas         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”— EvoluciÃ³n del Sistema

| Aspecto | SesiÃ³n 3 | SesiÃ³n 4 | SesiÃ³n 5 (prÃ³xima) |
|---------|----------|----------|-------------------|
| **Cola** | En memoria | Redis | Redis + Dead Letter |
| **Workers** | Threading | Multiprocessing | + Health checks |
| **Persistencia** | âŒ | âœ… | âœ… |
| **DistribuciÃ³n** | âŒ | âœ… | âœ… |
| **Auto-recovery** | âŒ | âŒ | âœ… |
| **Monitoreo** | Logs | redis-cli | Dashboard |

---

## ğŸ§ª Ejercicios Sugeridos (15 min)

### Ejercicio 1: Producer-Consumer Separado (FÃ¡cil)

Crear dos scripts que corren independientemente:
- `producer.py`: AÃ±ade tareas
- `consumer.py`: Procesa tareas

**Objetivo:** Entender desacoplamiento

### Ejercicio 2: Monitor de Cola (Medio)

Script que muestra estado en tiempo real:
```python
while True:
    stats = queue.get_stats()
    print(f"Pending: {stats['pending']}, Completed: {stats['completed']}")
    time.sleep(1)
```

**Objetivo:** Monitoreo en tiempo real

### Ejercicio 3: Recuperar Tarea Fallida (Avanzado)

Mover tarea de `failed` de vuelta a `pending`:
```python
failed_task_ids = redis_client.lrange('queue:failed', 0, -1)
for task_id in failed_task_ids:
    # Mover a pending...
```

**Objetivo:** Manejo de errores

---

## âœ… Checklist de Aprendizaje

Al final de la sesiÃ³n los estudiantes deberÃ­an poder:

- [ ] Conectar a Redis desde Python
- [ ] Crear y usar RedisTaskQueue
- [ ] Implementar RedisWorker
- [ ] Lanzar mÃºltiples workers con multiprocessing
- [ ] Usar redis-cli para inspeccionar cola
- [ ] Entender RPOPLPUSH
- [ ] Comparar threading vs multiprocessing

---

## ğŸ¯ PrÃ³xima SesiÃ³n

**SesiÃ³n 5: Health Checks y Auto-Recovery**
- Heartbeats de workers
- DetecciÃ³n de workers muertos
- Re-queue de tareas atascadas
- Dead letter queue
- Reintentos automÃ¡ticos

---

## ğŸ¤” Preguntas Frecuentes

### Â¿Por quÃ© no usar RabbitMQ o Kafka?

**Redis es suficiente para:**
- Colas simples
- Bajo-medio volumen
- Baja latencia

**RabbitMQ/Kafka son mejores para:**
- Alto volumen (millones/segundo)
- GarantÃ­as de entrega estrictas
- Sistemas crÃ­ticos

### Â¿Redis es suficientemente rÃ¡pido?

**SÃ­:**
- 100,000+ ops/segundo en hardware modesto
- Latencia: sub-milisegundo
- Para procesamiento de imÃ¡genes (segundos por tarea), Redis es mÃ¡s que suficiente

### Â¿QuÃ© pasa si Redis se cae?

**Sin persistencia (defecto):**
- Pierdes todas las tareas en memoria

**Con persistencia (RDB/AOF):**
- Redis guarda snapshots en disco
- Puedes recuperar tareas despuÃ©s de reinicio

Configurar persistencia:
```redis
# redis.conf
save 60 1000           # Guardar cada 60s si hay 1000+ cambios
appendonly yes         # AOF: log de todas las escrituras
```

### Â¿CÃ³mo escalar horizontalmente?

1. **Un Redis, mÃºltiples workers:**
   - Hasta ~100 workers
   - FÃ¡cil de implementar
   
2. **Redis Cluster:**
   - Miles de workers
   - Sharding automÃ¡tico
   - MÃ¡s complejo

3. **Redis Sentinel:**
   - Alta disponibilidad
   - Failover automÃ¡tico

Para este curso, un solo Redis es suficiente.

---

## ğŸ’¡ Tips de EnseÃ±anza

### 1. Demostrar Persistencia

```bash
# Terminal 1: AÃ±adir tareas
python producer.py

# Terminal 2: Ver en Redis
redis-cli LRANGE image_processing:pending 0 -1

# Terminal 3: Procesar
python consumer.py

# Terminal 2: Ver cambios en tiempo real
redis-cli MONITOR
```

### 2. Comparar con SesiÃ³n 3

Mostrar cÃ³digo lado a lado:
- `TaskQueue` vs `RedisTaskQueue`
- `SimpleWorker` vs `RedisWorker`
- Threading vs Multiprocessing

### 3. Visualizar con redis-cli

Abrir terminal separada con:
```bash
watch -n 1 'redis-cli LLEN image_processing:pending'
```

### 4. Simular Fallo de Worker

```python
# En RedisWorker.process_task()
if random.random() < 0.2:  # 20% de fallos
    raise Exception("Simulated failure")
```

Mostrar tareas en `failed`.

---

**Â¡Excelente trabajo! ğŸ”´**

Ahora los estudiantes tienen un sistema distribuido real con Redis.


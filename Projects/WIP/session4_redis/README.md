# ğŸ”´ SesiÃ³n 4: Redis y Colas Distribuidas

## ğŸ¯ Objetivos de Aprendizaje

Al final de esta sesiÃ³n podrÃ¡s:
- Conectar a Redis y usar colas distribuidas
- Implementar `RedisTaskQueue` para tareas persistentes
- Crear workers que procesen tareas desde Redis
- Ejecutar mÃºltiples workers en procesos separados
- Entender las ventajas de Redis sobre colas en memoria

---

## ğŸ“‹ Prerequisitos

- Haber completado SesiÃ³n 3 (Workers)
- Redis instalado y corriendo
- Python 3.8+

---

## ğŸš€ Setup

### 1. Instalar Redis

**macOS:**
```bash
brew install redis
redis-server
```

**Linux (Ubuntu/Debian):**
```bash
sudo apt update
sudo apt install redis-server
sudo systemctl start redis
```

**Docker (cualquier OS):**
```bash
docker run -d -p 6379:6379 --name redis redis:7-alpine
```

### 2. Verificar Redis

```bash
redis-cli ping
# DeberÃ­a responder: PONG
```

### 3. Instalar Dependencias Python

```bash
cd session4_redis
python3 -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

---

## ğŸ“‚ Estructura del Proyecto

```
session4_redis/
â”œâ”€â”€ requirements.txt           # Pillow + redis
â”œâ”€â”€ README.md                  # Este archivo
â”œâ”€â”€ GUIA_RAPIDA.md            # GuÃ­a del instructor
â”‚
â”œâ”€â”€ filters/                   # Filtros de imagen (de SesiÃ³n 2)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_filter.py
â”‚   â”œâ”€â”€ blur_filter.py
â”‚   â”œâ”€â”€ brightness_filter.py
â”‚   â”œâ”€â”€ edges_filter.py
â”‚   â””â”€â”€ grayscale_filter.py
â”‚
â”œâ”€â”€ core/                      # Pipeline (de SesiÃ³n 2)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ filter_pipeline.py
â”‚   â”œâ”€â”€ filter_factory.py
â”‚   â””â”€â”€ batch_processor.py
â”‚
â”œâ”€â”€ workers/                   # ğŸ†• Workers con Redis
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ redis_task_queue.py   # Cola en Redis
â”‚   â””â”€â”€ redis_worker.py       # Worker que lee de Redis
â”‚
â”œâ”€â”€ demos/
â”‚   â”œâ”€â”€ demo_redis_basic.py          # Demo bÃ¡sico con Redis
â”‚   â””â”€â”€ demo_distributed_workers.py  # Demo de workers distribuidos
â”‚
â”œâ”€â”€ images/
â”‚   â””â”€â”€ sample.jpg             # Imagen de ejemplo
â”‚
â””â”€â”€ output/                    # ImÃ¡genes procesadas
```

---

## ğŸ”´ Â¿QuÃ© es Redis?

**Redis** (REmote DIctionary Server) es una base de datos en memoria, open-source, que funciona como:
- Cola de mensajes
- Cache distribuido
- Base de datos key-value

### Â¿Por quÃ© Redis para colas de tareas?

| CaracterÃ­stica | TaskQueue (SesiÃ³n 3) | RedisTaskQueue (SesiÃ³n 4) |
|----------------|----------------------|---------------------------|
| **Persistencia** | âŒ Solo en memoria | âœ… Persistente en disco |
| **DistribuciÃ³n** | âŒ Un solo proceso | âœ… MÃºltiples mÃ¡quinas |
| **Atomicidad** | âœ… Thread-safe | âœ… Process-safe |
| **Escalabilidad** | âš ï¸ Limitada | âœ… Alta |
| **Reintentos** | âš ï¸ Manual | âœ… FÃ¡cil |
| **Monitoreo** | âš ï¸ Logs | âœ… Redis CLI |

---

## ğŸ“š Conceptos Clave

### 1. RedisTaskQueue

Cola de tareas distribuida usando Redis.

```python
from workers import RedisTaskQueue

# Conectar
queue = RedisTaskQueue(host='localhost', port=6379)

# AÃ±adir tarea
task_id = queue.add_task({
    'image_path': 'input.jpg',
    'output_path': 'output.jpg'
})

# Worker obtiene tarea (operaciÃ³n atÃ³mica)
task = queue.get_task('worker-1')

# Marcar como completada
queue.mark_completed(task_id, {'status': 'success'})

# Ver estadÃ­sticas
print(queue.get_stats())
```

**Estructura en Redis:**
- `queue:pending` (LIST): Tareas pendientes
- `queue:processing` (HASH): Tareas en proceso
- `queue:completed` (LIST): Tareas completadas
- `queue:failed` (LIST): Tareas fallidas
- `task:{id}` (HASH): Datos de cada tarea
- `result:{id}` (HASH): Resultados

### 2. OperaciÃ³n AtÃ³mica: RPOPLPUSH

Redis garantiza que solo un worker obtiene cada tarea usando `RPOPLPUSH`:

```redis
# Mueve tarea de 'pending' a 'processing' atÃ³micamente
RPOPLPUSH queue:pending queue:processing
```

Esto evita que dos workers procesen la misma tarea.

### 3. RedisWorker

Worker que procesa tareas de Redis:

```python
from workers import RedisWorker, RedisTaskQueue
from core import FilterPipeline
from filters import BlurFilter

# Conectar a Redis
queue = RedisTaskQueue(host='localhost')

# Crear pipeline
pipeline = FilterPipeline([BlurFilter()])

# Crear worker
worker = RedisWorker('worker-1', pipeline, queue)

# Procesar tareas
worker.start()  # Procesa hasta que la cola estÃ© vacÃ­a
```

---

## ğŸ¬ Demos

### Demo 1: Redis BÃ¡sico

```bash
python demos/demo_redis_basic.py
```

**QuÃ© muestra:**
- ConexiÃ³n a Redis
- AÃ±adir tareas a Redis
- Worker procesando tareas
- Persistencia de resultados
- InspecciÃ³n con redis-cli

### Demo 2: Workers Distribuidos

```bash
python demos/demo_distributed_workers.py
```

**QuÃ© muestra:**
- 3 workers en procesos separados (multiprocessing)
- 15 tareas distribuidas automÃ¡ticamente
- Speedup por paralelismo real (sin GIL)
- DistribuciÃ³n de carga entre workers

---

## ğŸ”§ Comandos Ãštiles de Redis

### redis-cli (Inspeccionar la Cola)

```bash
# Ver todas las keys
redis-cli KEYS "*"

# Ver tareas pendientes
redis-cli LRANGE image_processing:pending 0 -1

# Ver tareas en proceso
redis-cli HGETALL image_processing:processing

# Ver tareas completadas
redis-cli LRANGE image_processing:completed 0 -1

# Ver detalles de una tarea
redis-cli HGETALL task:TASK_ID

# Ver resultado de una tarea
redis-cli HGETALL result:TASK_ID

# Limpiar todas las keys
redis-cli FLUSHDB
```

### Monitorear Redis en Tiempo Real

```bash
# Ver todos los comandos ejecutÃ¡ndose
redis-cli MONITOR
```

---

## ğŸ”¬ ComparaciÃ³n: Redis vs TaskQueue

### Escenario: 15 tareas, 3 workers

| MÃ©trica | TaskQueue (threading) | RedisTaskQueue (multiprocessing) |
|---------|----------------------|----------------------------------|
| **Tiempo** | ~0.6s | ~0.4s |
| **Speedup** | ~2.4x | ~3.0x |
| **Eficiencia** | 80% | 95% |
| **Throughput** | 20 tareas/s | 30 tareas/s |
| **GIL** | âŒ Limitado por GIL | âœ… Sin GIL |
| **DistribuciÃ³n** | âŒ Una mÃ¡quina | âœ… MÃºltiples mÃ¡quinas |

---

## ğŸ’¡ Casos de Uso

### Â¿CuÃ¡ndo usar RedisTaskQueue?

âœ… **Usar cuando:**
- Necesitas persistencia (tareas sobreviven reinicios)
- MÃºltiples workers en diferentes mÃ¡quinas
- Alto volumen de tareas
- Necesitas monitoreo en tiempo real
- Workers pueden fallar y reiniciar

âŒ **No usar cuando:**
- AplicaciÃ³n simple de un solo proceso
- Latencia ultra-baja requerida (<1ms)
- No tienes Redis disponible

---

## ğŸ—ï¸ Arquitectura Distribuida

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API / Producer    â”‚
â”‚   (AÃ±ade tareas)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Redis         â”‚
â”‚   (Cola central)    â”‚
â”‚                     â”‚
â”‚  - pending: [...]   â”‚
â”‚  - processing: {...}â”‚
â”‚  - completed: [...]  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
     â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
     â”‚           â”‚
     â–¼           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Worker1 â”‚ â”‚ Worker2 â”‚
â”‚ (CPU 1) â”‚ â”‚ (CPU 2) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Flujo:**
1. Producer aÃ±ade tareas a Redis
2. Workers obtienen tareas (RPOPLPUSH atÃ³mico)
3. Workers procesan y guardan resultados en Redis
4. Producer puede consultar estado en cualquier momento

---

## ğŸ§ª Ejercicios PrÃ¡cticos

### Ejercicio 1: Producer-Consumer (FÃ¡cil)

Crea dos scripts separados:

**producer.py:**
```python
# AÃ±ade 10 tareas a Redis
queue = RedisTaskQueue()
for i in range(10):
    queue.add_task({'image_path': f'image{i}.jpg'})
print("Tareas aÃ±adidas")
```

**consumer.py:**
```python
# Worker que procesa tareas
worker = RedisWorker('worker-1', pipeline, queue)
worker.start()
```

EjecuciÃ³n:
```bash
# Terminal 1
python producer.py

# Terminal 2
python consumer.py
```

### Ejercicio 2: Monitoreo en Tiempo Real (Medio)

Crea un script que muestre el estado de la cola cada segundo:

```python
import time
from workers import RedisTaskQueue

queue = RedisTaskQueue()

while True:
    stats = queue.get_stats()
    print(f"Pending: {stats['pending']}, "
          f"Processing: {stats['processing']}, "
          f"Completed: {stats['completed']}")
    time.sleep(1)
```

### Ejercicio 3: Worker con Prioridades (Avanzado)

Modifica `RedisTaskQueue` para soportar prioridades:
- Alta prioridad: `queue:pending:high`
- Normal: `queue:pending:normal`
- Baja: `queue:pending:low`

Workers deben procesar tareas de alta prioridad primero.

---

## ğŸ› Troubleshooting

### Error: "Connection refused"

```python
ConnectionError: Error 61 connecting to localhost:6379. Connection refused.
```

**SoluciÃ³n:**
```bash
# Iniciar Redis
redis-server

# O con Docker
docker run -d -p 6379:6379 redis:7-alpine
```

### Error: "No module named 'redis'"

**SoluciÃ³n:**
```bash
pip install redis==5.0.1
```

### Tareas "atascadas" en processing

Si un worker crashea, las tareas quedan en `processing`.

**SoluciÃ³n manual:**
```bash
# Mover de processing a pending
redis-cli HKEYS image_processing:processing
redis-cli HDEL image_processing:processing TASK_ID
redis-cli RPUSH image_processing:pending TASK_ID
```

(En SesiÃ³n 5 veremos auto-recovery para esto)

---

## ğŸ“Š Performance Tips

### 1. Pipeline de Redis

Para operaciones mÃºltiples, usa pipelines:

```python
pipe = redis_client.pipeline()
pipe.rpush('queue:pending', task_id)
pipe.hset(f'task:{task_id}', mapping=task_data)
pipe.execute()  # Ejecuta todas las operaciones a la vez
```

### 2. ConexiÃ³n Persistente

Reutiliza la conexiÃ³n a Redis en lugar de crear una nueva cada vez.

### 3. Timeout Apropiado

```python
# Bloqueante (espera hasta que haya tarea)
task = queue.get_task('worker-1', timeout=5)

# No bloqueante (retorna None inmediatamente)
task = queue.get_task('worker-1', timeout=0)
```

---

## ğŸ¯ Resumen

### Lo que aprendiste:

âœ… Redis como cola de tareas distribuida  
âœ… `RedisTaskQueue` con operaciones atÃ³micas  
âœ… `RedisWorker` procesando desde Redis  
âœ… Multiprocessing para paralelismo real  
âœ… Persistencia de tareas y resultados  
âœ… Comandos de redis-cli para inspecciÃ³n  

### Diferencias clave vs SesiÃ³n 3:

| Aspecto | SesiÃ³n 3 | SesiÃ³n 4 |
|---------|----------|----------|
| Cola | En memoria | Redis (persistente) |
| Workers | Threading | Multiprocessing |
| GIL | Limitado | Sin impacto |
| DistribuciÃ³n | Una mÃ¡quina | MÃºltiples mÃ¡quinas |
| Monitoreo | Logs | redis-cli + Logs |

---

## ğŸ“š PrÃ³xima SesiÃ³n

**SesiÃ³n 5: Health Checks y Auto-Recovery**
- Workers que se auto-recuperan
- Heartbeats
- Dead letter queue
- Reintentos automÃ¡ticos

---

## ğŸ”— Referencias

- [Redis Documentation](https://redis.io/documentation)
- [redis-py (Python client)](https://redis-py.readthedocs.io/)
- [Redis Commands](https://redis.io/commands)
- [RPOPLPUSH (Atomic operation)](https://redis.io/commands/rpoplpush/)

---

**Â¡Felicidades!** ğŸ‰ Ahora tienes un sistema distribuido de procesamiento de imÃ¡genes con Redis.

